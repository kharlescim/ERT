{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "V28",
      "authorship_tag": "ABX9TyM9GiVxoQcrif4kB9exHX9i",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kharlescim/ERT_Project/blob/main/FI_scores.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "quick code to test which features are most informative for USDM"
      ],
      "metadata": {
        "id": "W2N5Gh-fl17B"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k0DD9oG3dwxP",
        "outputId": "d3c91fbf-98fd-47d4-eba5-3d53a759873f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting xarray\n",
            "  Downloading xarray-2025.7.1-py3-none-any.whl.metadata (12 kB)\n",
            "Collecting netCDF4\n",
            "  Downloading netCDF4-1.7.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.8 kB)\n",
            "Requirement already satisfied: numpy>=1.26 in /usr/local/lib/python3.11/dist-packages (from xarray) (2.0.2)\n",
            "Requirement already satisfied: packaging>=24.1 in /usr/local/lib/python3.11/dist-packages (from xarray) (25.0)\n",
            "Requirement already satisfied: pandas>=2.2 in /usr/local/lib/python3.11/dist-packages (from xarray) (2.2.2)\n",
            "Collecting cftime (from netCDF4)\n",
            "  Downloading cftime-1.6.4.post1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (8.7 kB)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from netCDF4) (2025.7.14)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas>=2.2->xarray) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=2.2->xarray) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=2.2->xarray) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas>=2.2->xarray) (1.17.0)\n",
            "Downloading xarray-2025.7.1-py3-none-any.whl (1.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m17.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading netCDF4-1.7.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (9.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.3/9.3 MB\u001b[0m \u001b[31m90.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading cftime-1.6.4.post1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m25.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: cftime, netCDF4, xarray\n",
            "Successfully installed cftime-1.6.4.post1 netCDF4-1.7.2 xarray-2025.7.1\n",
            "Collecting bottleneck\n",
            "  Downloading bottleneck-1.5.0-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (8.1 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from bottleneck) (2.0.2)\n",
            "Downloading bottleneck-1.5.0-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (361 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m361.2/361.2 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: bottleneck\n",
            "Successfully installed bottleneck-1.5.0\n"
          ]
        }
      ],
      "source": [
        "!pip install xarray netCDF4\n",
        "%pip install bottleneck"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import pandas as pd\n",
        "from sklearn.utils import class_weight\n",
        "from sklearn.metrics import classification_report\n",
        "import collections\n",
        "\n",
        "import xarray as xr\n",
        "import numpy as np\n",
        "\n",
        "LTD_ds = xr.open_dataset('LTD05.nc')\n",
        "spei_ds = xr.open_dataset('spei_obs_3D.nc')\n",
        "obs_ds = xr.open_dataset('obs.nc')\n",
        "\n",
        "LTD = LTD_ds['LTD']\n",
        "\n",
        "# Creating new time coordinate\n",
        "weekly_time = LTD_ds.time.values\n",
        "\n",
        "# Converting to weekly (method = linear)\n",
        "spei_weekly = spei_ds.interp(time=weekly_time, method=\"linear\")\n",
        "obs_weekly = obs_ds.interp(time=weekly_time, method=\"linear\")\n",
        "\n",
        "# Function to convert raw values to percentiles\n",
        "# missing values = -999 in obs - might need to alter for proper percentile (7-4)\n",
        "def to_percentile(ds, dim='time', missing_val = -999.0):\n",
        "\n",
        "    valid = ds.where(ds != missing_val)\n",
        "    # Convert each grid point's time series to percentile values.\n",
        "    return valid.rank(dim=dim, pct=True)\n",
        "\n",
        "percentiles_spei = to_percentile(spei_weekly)\n",
        "percentiles_obs = to_percentile(obs_weekly)\n",
        "\n",
        "# ens = 1, so safe to ignore it from dataset\n",
        "# testing flattening out entire dataset\n",
        "spei_df = percentiles_spei.to_dataframe().reset_index()\n",
        "LTD_df = LTD.to_dataframe().reset_index()\n",
        "obs_df = (percentiles_obs.to_dataframe().reset_index()).drop(columns=['ens'])\n",
        "merged_df = pd.merge(spei_df, obs_df, on=['time', 'lat', 'lon'], how='inner')\n",
        "merged_df = pd.merge(merged_df, LTD_df, on=['time', 'lat', 'lon'], how='inner')\n",
        "\n",
        "# cleaning up NaN entries\n",
        "df = merged_df.dropna().copy()\n",
        "\n",
        "# changing -1 classification to 5 to work with featurespace\n",
        "df[\"LTD\"] = df[\"LTD\"].replace(-1, 5)\n",
        "\n",
        "from sklearn.feature_selection import mutual_info_classif\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "\n",
        "# Extract features and target\n",
        "X = df.drop(columns=[\"LTD\", \"time\", \"lat\", \"lon\"])\n",
        "y = df[\"LTD\"]\n",
        "\n",
        "# Scale inputs to [0, 1] if needed (helps MI estimator)\n",
        "X_scaled = pd.DataFrame(MinMaxScaler().fit_transform(X), columns=X.columns)\n",
        "\n",
        "# Compute MI\n",
        "mi_scores = mutual_info_classif(X_scaled, y, discrete_features=False, random_state=42)\n",
        "\n",
        "from sklearn.metrics import mutual_info_score\n",
        "from scipy.stats import entropy\n",
        "\n",
        "# Calculate entropy of the target\n",
        "target_probs = df[\"LTD\"].value_counts(normalize=True).values\n",
        "H_y = entropy(target_probs, base=2)  # bits\n",
        "\n",
        "fi_scores = mi_scores / H_y\n",
        "\n",
        "for name, fi in zip(X.columns, fi_scores):\n",
        "    print(f\"{name}: FI = {fi:.4f}\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jt-5NmDAd1tb",
        "outputId": "8d8784d7-ccaa-4793-c614-99dd73d83b36"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SPEI1: FI = 0.0046\n",
            "SPEI3: FI = 0.0153\n",
            "SPEI6: FI = 0.0378\n",
            "SPEI12: FI = 0.0746\n",
            "SPEI24: FI = 0.0691\n",
            "SPEI60: FI = 0.0355\n",
            "SPEI2: FI = 0.0097\n",
            "SPEI9: FI = 0.0619\n",
            "SPEI36: FI = 0.0590\n",
            "SPEI48: FI = 0.0460\n",
            "SPEI72: FI = 0.0300\n",
            "SPI1: FI = 0.0004\n",
            "SPI3: FI = 0.0049\n",
            "SPI6: FI = 0.0220\n",
            "SPI9: FI = 0.0465\n",
            "SPI12: FI = 0.0633\n",
            "SPI24: FI = 0.0599\n",
            "SPI60: FI = 0.0260\n",
            "SMP1: FI = 0.0402\n",
            "SMP3: FI = 0.0526\n",
            "SMP6: FI = 0.0643\n",
            "SMP9: FI = 0.0676\n",
            "SMP12: FI = 0.0634\n",
            "SMP24: FI = 0.0401\n",
            "SMP60: FI = 0.0181\n",
            "SRI1: FI = 0.0158\n",
            "SRI3: FI = 0.0282\n",
            "SRI6: FI = 0.0463\n",
            "SRI9: FI = 0.0615\n",
            "SRI12: FI = 0.0646\n",
            "SRI24: FI = 0.0404\n",
            "SRI60: FI = 0.0127\n"
          ]
        }
      ]
    }
  ]
}