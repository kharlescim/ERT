{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN+kTmEDlxcdaQifCIVFklE",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kharlescim/ERT/blob/main/ERT_Project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Colab Purpose**\n",
        "This colab will mainly be used for documenting my thoughts and manipulating the datasets using xarray, as it's easier to quickly visualize and print information from the datasets in this environment. However, training the model on colab takes wayyy too much RAM, enough to crash after just one epoch. As such, training will be done on a different .py file in the repo, although the code will still be written here. For now, all my thoughts and documentation, including on the training done from my machine, will be here. the .py code is just to run the model."
      ],
      "metadata": {
        "id": "CweBIi78uYQM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Loading and printing datasets from nc files**"
      ],
      "metadata": {
        "id": "x1Ullqt71_L4"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UNEg14JAzveM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "outputId": "cbb12926-019d-41f4-c5a2-6612c1a8be60"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: xarray in /usr/local/lib/python3.11/dist-packages (2025.3.1)\n",
            "Requirement already satisfied: netCDF4 in /usr/local/lib/python3.11/dist-packages (1.7.2)\n",
            "Requirement already satisfied: numpy>=1.24 in /usr/local/lib/python3.11/dist-packages (from xarray) (2.0.2)\n",
            "Requirement already satisfied: packaging>=23.2 in /usr/local/lib/python3.11/dist-packages (from xarray) (24.2)\n",
            "Requirement already satisfied: pandas>=2.1 in /usr/local/lib/python3.11/dist-packages (from xarray) (2.2.2)\n",
            "Requirement already satisfied: cftime in /usr/local/lib/python3.11/dist-packages (from netCDF4) (1.6.4.post1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from netCDF4) (2025.6.15)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas>=2.1->xarray) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=2.1->xarray) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=2.1->xarray) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas>=2.1->xarray) (1.17.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install xarray netCDF4\n",
        "\n",
        "import xarray as xr\n",
        "import numpy as np\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "LTD_ds = xr.open_dataset('LTD05.nc')\n",
        "USDM05_ds = xr.open_dataset('USDM05_2000_2024.nc')\n",
        "obs_ds = xr.open_dataset('obs.nc')\n",
        "spei_ds = xr.open_dataset('spei_obs_3D.nc')\n",
        "\n",
        "\n",
        "# LTD and USDM only have one variable, so they can be treated as DataArrays\n",
        "LTD = LTD_ds['LTD']\n",
        "USDM = USDM05_ds['USDM']\n",
        "print(LTD)\n",
        "print(USDM)\n",
        "print(obs_ds)\n",
        "print(spei_ds)\n",
        "\n"
      ],
      "metadata": {
        "id": "tspGBjKZzzG_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "outputId": "08726323-91a1-4508-d8c2-d756ba8bbf87"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<xarray.DataArray 'LTD' (time: 1305, lat: 48, lon: 118)> Size: 30MB\n",
            "[7391520 values with dtype=float32]\n",
            "Coordinates:\n",
            "  * lon      (lon) float32 472B -125.8 -125.2 -124.8 ... -68.25 -67.75 -67.25\n",
            "  * lat      (lat) float32 192B 25.25 25.75 26.25 26.75 ... 47.75 48.25 48.75\n",
            "  * time     (time) datetime64[ns] 10kB 2000-01-04 2000-01-11 ... 2024-12-31\n",
            "<xarray.DataArray 'USDM' (time: 1305, lat: 48, lon: 118)> Size: 30MB\n",
            "[7391520 values with dtype=float32]\n",
            "Coordinates:\n",
            "  * lon      (lon) float32 472B -125.8 -125.2 -124.8 ... -68.25 -67.75 -67.25\n",
            "  * lat      (lat) float32 192B 25.25 25.75 26.25 26.75 ... 47.75 48.25 48.75\n",
            "  * time     (time) datetime64[ns] 10kB 2000-01-04 2000-01-11 ... 2024-12-31\n",
            "<xarray.Dataset> Size: 193MB\n",
            "Dimensions:  (lon: 118, lat: 48, ens: 1, time: 406)\n",
            "Coordinates:\n",
            "  * lon      (lon) float32 472B -125.8 -125.2 -124.8 ... -68.25 -67.75 -67.25\n",
            "  * lat      (lat) float32 192B 25.25 25.75 26.25 26.75 ... 47.75 48.25 48.75\n",
            "  * ens      (ens) float32 4B 1.0\n",
            "  * time     (time) datetime64[ns] 3kB 1991-01-01 1991-02-01 ... 2024-10-01\n",
            "Data variables: (12/21)\n",
            "    SPI1     (time, ens, lat, lon) float32 9MB ...\n",
            "    SPI3     (time, ens, lat, lon) float32 9MB ...\n",
            "    SPI6     (time, ens, lat, lon) float32 9MB ...\n",
            "    SPI9     (time, ens, lat, lon) float32 9MB ...\n",
            "    SPI12    (time, ens, lat, lon) float32 9MB ...\n",
            "    SPI24    (time, ens, lat, lon) float32 9MB ...\n",
            "    ...       ...\n",
            "    SRI3     (time, ens, lat, lon) float32 9MB ...\n",
            "    SRI6     (time, ens, lat, lon) float32 9MB ...\n",
            "    SRI9     (time, ens, lat, lon) float32 9MB ...\n",
            "    SRI12    (time, ens, lat, lon) float32 9MB ...\n",
            "    SRI24    (time, ens, lat, lon) float32 9MB ...\n",
            "    SRI60    (time, ens, lat, lon) float32 9MB ...\n",
            "Attributes:\n",
            "    Title:        Monthly Drought Indices based on Observations/Analysis\n",
            "    Variables:    SPI: Standardized Precipitation Index; SMP: Soil Moisture P...\n",
            "    Units:        Unitless for SPI and SRI, % for SMP\n",
            "    Valid_range:  -4 to 4 for SPI and SRI, 0 to 100 for SMP\n",
            "    Note:         The monthly drought indices (01/1991-present) were computed...\n",
            "<xarray.Dataset> Size: 101MB\n",
            "Dimensions:  (time: 404, lat: 48, lon: 118)\n",
            "Coordinates:\n",
            "  * time     (time) datetime64[ns] 3kB 1991-01-31 1991-02-28 ... 2024-08-31\n",
            "  * lat      (lat) float32 192B 25.25 25.75 26.25 26.75 ... 47.75 48.25 48.75\n",
            "  * lon      (lon) float32 472B -125.8 -125.2 -124.8 ... -68.25 -67.75 -67.25\n",
            "Data variables:\n",
            "    SPEI1    (time, lat, lon) float32 9MB ...\n",
            "    SPEI3    (time, lat, lon) float32 9MB ...\n",
            "    SPEI6    (time, lat, lon) float32 9MB ...\n",
            "    SPEI12   (time, lat, lon) float32 9MB ...\n",
            "    SPEI24   (time, lat, lon) float32 9MB ...\n",
            "    SPEI60   (time, lat, lon) float32 9MB ...\n",
            "    SPEI2    (time, lat, lon) float32 9MB ...\n",
            "    SPEI9    (time, lat, lon) float32 9MB ...\n",
            "    SPEI36   (time, lat, lon) float32 9MB ...\n",
            "    SPEI48   (time, lat, lon) float32 9MB ...\n",
            "    SPEI72   (time, lat, lon) float32 9MB ...\n",
            "Attributes:\n",
            "    Variables:   SPEI: Standardized Prcp. Evap. Index ;  \n",
            "    Contacts:    Dr. Li Xu     li.xu@noaa.gov\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**General Knowledge** <br>\n",
        "- LTD = Long Term Drought (already in USDM format)\n",
        "- USDM = USDM Rasterdized Data\n",
        "- obs = VIC Model Drought Index\n",
        "- spei = SPEI Drought Index\n",
        "\n",
        "LTD & USDM have weekly temporal frequency, obs and spei are monthly. also obs and spei have multiple variables and should be treated as datasets, while LTD and USDM can simply be treated as dataarrays\n",
        "\n",
        "**Data Cleanup TODO** <br>\n",
        "interpolate OBS and SPEI data into monthly data (method = linear)<br>\n",
        "standardize all datasets using USDM categorical distribution <br>\n",
        "see how plot animation changes between tasks\n"
      ],
      "metadata": {
        "id": "4Xm_813Hz1m5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Interpolating Data**"
      ],
      "metadata": {
        "id": "KcOAWxdH_Ed_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Checking date ranges\n",
        "print(obs_ds.time.values[0])\n",
        "print(obs_ds.time.values[-1])\n",
        "print(spei_ds.time.values[0])\n",
        "print(spei_ds.time.values[-1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dXfRuP7V_RHp",
        "outputId": "6d0adce1-ddf3-4388-dabd-25c36263ae6f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1991-01-01T00:00:00.000000000\n",
            "2024-10-01T00:00:00.000000000\n",
            "1991-01-31T00:00:00.000000000\n",
            "2024-08-31T00:00:00.000000000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating new time coordinate\n",
        "weekly_time = pd.date_range(\n",
        "    start=obs_ds.time.values[0],\n",
        "    end=obs_ds.time.values[-1],\n",
        "    freq='W'  # weekly frequency\n",
        ")\n",
        "\n",
        "# Converting to weekly (method = linear)\n",
        "obs_weekly = obs_ds.interp(time=weekly_time, method=\"linear\")\n",
        "spei_weekly = spei_ds.interp(time=weekly_time, method=\"linear\")\n",
        "\n"
      ],
      "metadata": {
        "id": "aQa5gwQF2MTy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Converting to Categorical USDM using Percentiles**\n",
        "- CONSIDER DOING - add another category for NaN/non-drought values, so we can better visualize drought vs non-drought areas on map\n",
        "  - when visualizing USDM-converted datasets, the border of map also completely disappears"
      ],
      "metadata": {
        "id": "edF13qGhCSyt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to convert raw values to percentiles\n",
        "def to_percentile(ds, dim='time'):\n",
        "    # Convert each grid point's time series to percentile values.\n",
        "    return ds.rank(dim=dim, pct=True)\n",
        "\n",
        "# Function to bucket entries w/ specific percentiles in matching usdm categories\n",
        "def percentile_to_USDM(p):\n",
        "  return xr.where(p <= 0.02, 4,           # D4 (Exceptional Drought) = .00-.02\n",
        "           xr.where(p <= 0.05, 3,         # D3 (Extreme Drought) = .02-.05\n",
        "           xr.where(p <= 0.10, 2,         # D2 (Severe Drought) = .05-.10\n",
        "           xr.where(p <= 0.20, 1, 0))))   # D1 (Moderate Drought) = .1-.2, else D0 (Abnormally Dry)\n",
        "\n",
        "\n",
        "percentiles_obs = to_percentile(obs_weekly)\n",
        "USDM_obs = percentile_to_USDM(percentiles_obs)\n",
        "percentiles_spei = to_percentile(spei_weekly)\n",
        "USDM_spei = percentile_to_USDM(percentiles_spei)"
      ],
      "metadata": {
        "id": "jYGWZwNaCY0r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "quick verification"
      ],
      "metadata": {
        "id": "kTxYqP0uGPyY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# print(USDM_obs)\n",
        "# print(USDM_spei)\n",
        "print(USDM_obs.to_array().mean().item())\n",
        "print((USDM_obs.to_array() > 0).sum().item())\n",
        "print(USDM_spei.to_array().mean().item())\n",
        "print((USDM_spei.to_array() > 0).sum().item())"
      ],
      "metadata": {
        "id": "MECdmgxsEYla"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Visualizing Datasets w/ Animations**"
      ],
      "metadata": {
        "id": "jasJg1cJ3KIB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "to be used to animate USDM datasets (for now, just visualizing LTD and USDM)"
      ],
      "metadata": {
        "id": "I7iljEpuTh12"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import HTML\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.animation as animation\n",
        "from matplotlib.colors import BoundaryNorm\n",
        "import matplotlib.cm as cm\n",
        "\n",
        "fig, ax = plt.subplots()\n",
        "\n",
        "# Discrete colormap and norm for categories 0–4\n",
        "bounds = [0, 1, 2, 3, 4, 5]\n",
        "cmap = cm.get_cmap(\"magma\", len(bounds) - 1)\n",
        "norm = BoundaryNorm(bounds, cmap.N)\n",
        "\n",
        "cbar = None\n",
        "\n",
        "# Define the update function\n",
        "def animate_USDM(data, i):\n",
        "    global cbar\n",
        "    ax.clear()\n",
        "\n",
        "    # Store the plot object\n",
        "    # Plot with discrete colormap and norm\n",
        "    plot_obj = data.isel(time=i).plot(\n",
        "        ax=ax,\n",
        "        cmap=cmap,\n",
        "        norm=norm,\n",
        "        add_colorbar=False\n",
        "    )\n",
        "\n",
        "    # Add static colorbar once\n",
        "    if cbar is None:\n",
        "        cbar = fig.colorbar(\n",
        "            plot_obj,\n",
        "            ax=ax,\n",
        "            boundaries=bounds,\n",
        "            ticks=range(5),\n",
        "            label='USDM Category'\n",
        "        )\n",
        "        cbar.ax.set_yticklabels(['D0', 'D1', 'D2', 'D3', 'D4'])\n",
        "\n",
        "    ax.set_title(str(data.time[i].values)[:10])\n",
        "    ax.set_title(str(data.time[i].values)[:10])\n",
        "    # Return the plot object\n",
        "    return plot_obj"
      ],
      "metadata": {
        "id": "6U85x2e_TNjU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# plotting raw LTD dataset (LTD is already in USDM range)\n",
        "anim_LTD = animation.FuncAnimation(fig, lambda i: animate_USDM(LTD, i), frames=len(LTD.time), interval=100)\n",
        "HTML(anim_LTD.to_html5_video())"
      ],
      "metadata": {
        "id": "E2ClUK7rHQHY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# plotting raw USDM dataset\n",
        "anim_USDM = animation.FuncAnimation(fig, lambda i: animate_USDM(USDM, i), frames=len(USDM.time), interval=100)\n",
        "HTML(anim_USDM.to_html5_video())"
      ],
      "metadata": {
        "id": "c3-nFrRnJoF4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Training an MI Model using Keras** <br>\n",
        "For now, we'll train the model following the basic examples using the utilities given by Keras, such as FeatureSpace. Later if needed, we can try implementing the model from scratch to better manage parameters\n",
        "\n",
        "Possible examples from Keras: <br>\n",
        "- **Structured Data Classification using FeatureSpace**\n",
        "  - predict USDM drought class from lat/lon/time\n",
        "- Timeseries Classification (pdf notes that these are potentially valuable, but weren't particularly studied)\n",
        "  - predict future LTD values from past LTD datasets/values\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "ty0sceqW2NCO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "importing relevant keras stuff"
      ],
      "metadata": {
        "id": "sMqCcOP0VkaS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "os.environ[\"KERAS_BACKEND\"] = \"tensorflow\"\n",
        "import tensorflow as tf\n",
        "import keras\n",
        "from keras.utils import FeatureSpace"
      ],
      "metadata": {
        "id": "bZENzKMO3IVp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "converting and cleaning LTD to dataframe <br>\n",
        "**Important:** changing datetime to Unix epoch format for use with TensorFlow\n",
        "- may want to later extract month + day values. for now this is what we got\n",
        "\n",
        "also changing LTD to be int"
      ],
      "metadata": {
        "id": "5W1TVrklVoe0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "LTD_df = LTD.to_dataframe().reset_index()\n",
        "print(np.sort(LTD_df['LTD'].unique()))\n",
        "\n",
        "# cleaning up NaN entries and -1 entries\n",
        "df = LTD_df.dropna(subset=['LTD'])\n",
        "df = df[df['LTD'] != -1.0]\n",
        "\n",
        "#visualizing\n",
        "print(df['LTD'].value_counts().sort_index())\n",
        "\n",
        "\n",
        "# changing datetime to be usable by TensorFlow, changing LTD from float to int to match example\n",
        "df[\"time\"] = pd.to_datetime(df[\"time\"]).map(pd.Timestamp.timestamp)\n",
        "df[\"LTD\"] = df[\"LTD\"].astype(int)\n",
        "df.head() # LTD is target"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 354
        },
        "id": "O84NKRSfVrKE",
        "outputId": "4d79a275-ef95-4f08-dfa8-9aac7644410f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[-1.  0.  1.  2.  3.  4. nan]\n",
            "LTD\n",
            "0.0    314663\n",
            "1.0    310012\n",
            "2.0    338081\n",
            "3.0    216478\n",
            "4.0     82860\n",
            "Name: count, dtype: int64\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "               time    lat    lon  LTD\n",
              "147554  962668800.0  26.25 -98.75    1\n",
              "147555  962668800.0  26.25 -98.25    1\n",
              "147556  962668800.0  26.25 -97.75    1\n",
              "147557  962668800.0  26.25 -97.25    1\n",
              "147671  962668800.0  26.75 -99.25    1"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-5d09517d-8bd4-4e08-8e3b-a4b95bca61fe\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>time</th>\n",
              "      <th>lat</th>\n",
              "      <th>lon</th>\n",
              "      <th>LTD</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>147554</th>\n",
              "      <td>962668800.0</td>\n",
              "      <td>26.25</td>\n",
              "      <td>-98.75</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>147555</th>\n",
              "      <td>962668800.0</td>\n",
              "      <td>26.25</td>\n",
              "      <td>-98.25</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>147556</th>\n",
              "      <td>962668800.0</td>\n",
              "      <td>26.25</td>\n",
              "      <td>-97.75</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>147557</th>\n",
              "      <td>962668800.0</td>\n",
              "      <td>26.25</td>\n",
              "      <td>-97.25</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>147671</th>\n",
              "      <td>962668800.0</td>\n",
              "      <td>26.75</td>\n",
              "      <td>-99.25</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-5d09517d-8bd4-4e08-8e3b-a4b95bca61fe')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-5d09517d-8bd4-4e08-8e3b-a4b95bca61fe button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-5d09517d-8bd4-4e08-8e3b-a4b95bca61fe');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-3ea536c9-e9a5-478b-bce4-971dc73fc13a\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-3ea536c9-e9a5-478b-bce4-971dc73fc13a')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-3ea536c9-e9a5-478b-bce4-971dc73fc13a button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df"
            }
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Applying Keras Structured Data Classification w/ Feature Space to cleaned LTD dataframe**"
      ],
      "metadata": {
        "id": "HZZz1PRIY8iI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "splitting data into training + validation set"
      ],
      "metadata": {
        "id": "UKqcphLvZzKG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "val_df = df.sample(frac=0.2, random_state=1337)\n",
        "train_df = df.drop(val_df.index)\n",
        "\n",
        "print(\n",
        "    \"Using %d samples for training and %d for validation\"\n",
        "    % (len(train_df), len(val_df))\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nu38z7MeZD3Y",
        "outputId": "338b7f0f-48ef-462c-d5ab-c58cde646185"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using 1009675 samples for training and 252419 for validation\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Generating tf.data.Dataset for each dataframe, where each Dataset yields a tuple (input, target). <br>\n",
        "Input is a dictionary of features, target (LTD) is a value 0-4 <br>"
      ],
      "metadata": {
        "id": "7EaN-wHGZ2pa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def dataframe_to_dataset(dataframe):\n",
        "    dataframe = dataframe.copy()\n",
        "    labels = dataframe.pop(\"LTD\")\n",
        "    ds = tf.data.Dataset.from_tensor_slices((dict(dataframe), labels))\n",
        "    ds = ds.shuffle(buffer_size=len(dataframe))\n",
        "    return ds\n",
        "\n",
        "\n",
        "train_ds = dataframe_to_dataset(train_df)\n",
        "val_ds = dataframe_to_dataset(val_df)\n",
        "\n",
        "for x, y in train_ds.take(1):\n",
        "    print(\"Input:\", x)\n",
        "    print(\"Target:\", y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N4lKwFNOaOen",
        "outputId": "19b7bbe7-2074-466f-f45b-0411294a5800"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input: {'time': <tf.Tensor: shape=(), dtype=float64, numpy=1041292800.0>, 'lat': <tf.Tensor: shape=(), dtype=float32, numpy=36.25>, 'lon': <tf.Tensor: shape=(), dtype=float32, numpy=-111.75>}\n",
            "Target: tf.Tensor(4, shape=(), dtype=int64)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Batching Datasets"
      ],
      "metadata": {
        "id": "D8FzVkbqduil"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_ds = train_ds.batch(16)\n",
        "val_ds = val_ds.batch(16)"
      ],
      "metadata": {
        "id": "sgyybyMBdwBY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Configuring our FeatureSpace\n",
        "- for now, features are pretty barebones. just as they are in original dataframe"
      ],
      "metadata": {
        "id": "vdnNudsrewzc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "feature_space = FeatureSpace(\n",
        "    features={\n",
        "        \"lat\": \"float\",\n",
        "        \"lon\": \"float\",\n",
        "        \"time\": \"float\",\n",
        "    },\n",
        "    output_mode=\"concat\"\n",
        ")"
      ],
      "metadata": {
        "id": "r6CIB3oZe8MG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Adapting FeatureSpace to training data"
      ],
      "metadata": {
        "id": "QdSpBFO2fg4W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_ds_with_no_labels = train_ds.map(lambda x, _: x)\n",
        "feature_space.adapt(train_ds_with_no_labels)\n",
        "\n",
        "for x, _ in train_ds.take(1):\n",
        "    preprocessed_x = feature_space(x)\n",
        "    print(\"preprocessed_x.shape:\", preprocessed_x.shape)\n",
        "    print(\"preprocessed_x.dtype:\", preprocessed_x.dtype)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N9E-yXbAfjSt",
        "outputId": "516e02ba-738e-43ea-803c-200e1b3eb339"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "preprocessed_x.shape: (16, 3)\n",
            "preprocessed_x.dtype: <dtype: 'float32'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Manage preprocessing in tf.data pipeline"
      ],
      "metadata": {
        "id": "x6C9P9cug6Z3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "preprocessed_train_ds = train_ds.map(\n",
        "    lambda x, y: (feature_space(x), y), num_parallel_calls=tf.data.AUTOTUNE\n",
        ")\n",
        "preprocessed_train_ds = preprocessed_train_ds.prefetch(tf.data.AUTOTUNE)\n",
        "\n",
        "preprocessed_val_ds = val_ds.map(\n",
        "    lambda x, y: (feature_space(x), y), num_parallel_calls=tf.data.AUTOTUNE\n",
        ")\n",
        "preprocessed_val_ds = preprocessed_val_ds.prefetch(tf.data.AUTOTUNE)"
      ],
      "metadata": {
        "id": "_cabw0Awg9je"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Build training & Inference Model"
      ],
      "metadata": {
        "id": "wCTtQ_BahD18"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dict_inputs = feature_space.get_inputs()\n",
        "encoded_features = feature_space.get_encoded_features()\n",
        "\n",
        "x = keras.layers.Dense(32, activation=\"relu\")(encoded_features)\n",
        "x = keras.layers.Dropout(0.5)(x)\n",
        "# change from example in order to fit categorization of LTD\n",
        "predictions = keras.layers.Dense(5, activation=\"softmax\")(x)\n",
        "\n",
        "training_model = keras.Model(inputs=encoded_features, outputs=predictions)\n",
        "training_model.compile(\n",
        "    optimizer=\"adam\", loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"] # change this too to from binary\n",
        ")\n",
        "\n",
        "inference_model = keras.Model(inputs=dict_inputs, outputs=predictions)"
      ],
      "metadata": {
        "id": "_ErVn_pIhGTq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Train Model for 20 Epochs"
      ],
      "metadata": {
        "id": "bFW-Mj7hhHlD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "From tests on my own machine, accuracy plateaus at 0.2678 at the second or third epoch, indicating that while the model is more accurate than pure random (1/5 chance), it suffers from underfitting/not being able to discern enough information well enough to predict correctly past a certain threshold. While this could be attributed to how the model was trained, I think it's more likely because it was only trained on the features given by LTD, which were lat, lon, and timezone (converted into Unix Epoch to account for TensorFlow) - not really good indicators for when a drought would come. I think the model would need to be trained on the other .nc files to be more accurate, but it could still be an issue with how I trained the model. need to ask."
      ],
      "metadata": {
        "id": "C0bnbD9FuUf9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "training_model.fit(\n",
        "    preprocessed_train_ds,\n",
        "    epochs=20,\n",
        "    validation_data=preprocessed_val_ds,\n",
        "    verbose=2,\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 522
        },
        "id": "_o-HEj9LhKZS",
        "outputId": "7cf5997b-5b15-47c0-960f-4fd5772826a7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "63105/63105 - 135s - 2ms/step - accuracy: 0.2457 - loss: -1.0368e+13 - val_accuracy: 0.2456 - val_loss: -2.9856e+13\n",
            "Epoch 2/20\n",
            "63105/63105 - 139s - 2ms/step - accuracy: 0.2456 - loss: -6.7129e+13 - val_accuracy: 0.2456 - val_loss: -1.1327e+14\n",
            "Epoch 3/20\n",
            "63105/63105 - 149s - 2ms/step - accuracy: 0.2456 - loss: -1.7696e+14 - val_accuracy: 0.2456 - val_loss: -2.4970e+14\n",
            "Epoch 4/20\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-15-623817785.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m training_model.fit(\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mpreprocessed_train_ds\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpreprocessed_val_ds\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    115\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 117\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    118\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/backend/tensorflow/trainer.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)\u001b[0m\n\u001b[1;32m    369\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterator\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mepoch_iterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    370\u001b[0m                     \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 371\u001b[0;31m                     \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    372\u001b[0m                     \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    373\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_training\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/backend/tensorflow/trainer.py\u001b[0m in \u001b[0;36mfunction\u001b[0;34m(iterator)\u001b[0m\n\u001b[1;32m    217\u001b[0m                 \u001b[0miterator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistribute\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDistributedIterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m             ):\n\u001b[0;32m--> 219\u001b[0;31m                 \u001b[0mopt_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmulti_step_on_iterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    220\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mopt_outputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhas_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    221\u001b[0m                     \u001b[0;32mraise\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    831\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    832\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 833\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    834\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    835\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    876\u001b[0m       \u001b[0;31m# In this case we have not created variables on the first call. So we can\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    877\u001b[0m       \u001b[0;31m# run the first trace but we should fail if variables are created.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 878\u001b[0;31m       results = tracing_compilation.call_function(\n\u001b[0m\u001b[1;32m    879\u001b[0m           \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variable_creation_config\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    880\u001b[0m       )\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py\u001b[0m in \u001b[0;36mcall_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    137\u001b[0m   \u001b[0mbound_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m   \u001b[0mflat_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munpack_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbound_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 139\u001b[0;31m   return function._call_flat(  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m    140\u001b[0m       \u001b[0mflat_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m   )\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[1;32m   1320\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1321\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1322\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_inference_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_preflattened\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1323\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1324\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py\u001b[0m in \u001b[0;36mcall_preflattened\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m    214\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mcall_preflattened\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mSequence\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m     \u001b[0;34m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 216\u001b[0;31m     \u001b[0mflat_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpack_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflat_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py\u001b[0m in \u001b[0;36mcall_flat\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    249\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mrecord\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_recording\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m           \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_bound_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 251\u001b[0;31m             outputs = self._bound_context.call_function(\n\u001b[0m\u001b[1;32m    252\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    253\u001b[0m                 \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/context.py\u001b[0m in \u001b[0;36mcall_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1681\u001b[0m     \u001b[0mcancellation_context\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcancellation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1682\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcancellation_context\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1683\u001b[0;31m       outputs = execute.execute(\n\u001b[0m\u001b[1;32m   1684\u001b[0m           \u001b[0mname\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"utf-8\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1685\u001b[0m           \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     54\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     55\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    }
  ]
}